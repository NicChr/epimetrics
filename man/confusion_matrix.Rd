% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/confusion_matrix.R
\name{confusion_matrix}
\alias{confusion_matrix}
\title{Confusion matrix}
\usage{
confusion_matrix(outcome, prediction)
}
\arguments{
\item{outcome}{Vector of outcome/response/actual classes. e.g. 0, 1.}

\item{prediction}{Vector of predicted classes. e.g. "A", "B".}
}
\value{
An n x m \code{matrix} where \code{n} is the number of
distinct predicted classes and \code{m} is the number of
distinct outcome classes.
}
\description{
Wrapper around \code{table()} that
creates an n x m confusion matrix of the number of
correct and incorrect classes of a multi-class variable where
n is the number of distinct predicted classes and m is the
number of distinct outcome classes.
The only difference between \code{confusion_matrix()} and \code{table()}
is that it sorts the rows and columns
of the predicted and actual classes respectively in descending order,
similar to the way that confusion matrices are usually presented.
}
\examples{
library(epimetrics)
library(MASS)

pima_train <- Pima.tr # Training data set
pima_test <- Pima.te # Test data set

rf_train <- glm(type ~ ., data = pima_train, family = "binomial")
rf_prob_scores <- predict(rf_train, newdata = pima_test,
                          type = "response")
# Typically you will use an ROC curve to determine best cutoff
rf_predictions <- ifelse(rf_prob_scores >= 0.5, 1, 0)
outcomes <- pima_test$type
cm <- confusion_matrix(outcomes, rf_predictions)
cm
epimetrics(cm)
}
